<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />

    

    
    <title>03机器学习实战-第3章 决策树 | Matrix</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
        <meta name="keywords" content="机器学习" />
    
    <meta name="description" content="[TOC] 第3章 决策树本章内容  决策树简介   在数据集中度量一致性   使用递归构造决策树      使用Matplotlib绘制树形图      决策树的构造 优点：计算复杂度不高，输出易于理解，对中间值得确实不敏感，可以处理不相关特征数据。缺点：可能会产生过度匹配问题使用数据类型：数值型和标称型    创建分支伪代码函数createBranch()如下：123456789检测数据集中的">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="03机器学习实战-第3章 决策树">
<meta property="og:url" content="http://matrixgardener.github.io/2018/01/28/03机器学习实战-第3章 决策树/index.html">
<meta property="og:site_name" content="Matrix">
<meta property="og:description" content="[TOC] 第3章 决策树本章内容  决策树简介   在数据集中度量一致性   使用递归构造决策树      使用Matplotlib绘制树形图      决策树的构造 优点：计算复杂度不高，输出易于理解，对中间值得确实不敏感，可以处理不相关特征数据。缺点：可能会产生过度匹配问题使用数据类型：数值型和标称型    创建分支伪代码函数createBranch()如下：123456789检测数据集中的">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-4a601bdc74abb553c0873fbd61597035_hd.jpg">
<meta property="og:updated_time" content="2018-08-04T10:29:38.683Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="03机器学习实战-第3章 决策树">
<meta name="twitter:description" content="[TOC] 第3章 决策树本章内容  决策树简介   在数据集中度量一致性   使用递归构造决策树      使用Matplotlib绘制树形图      决策树的构造 优点：计算复杂度不高，输出易于理解，对中间值得确实不敏感，可以处理不相关特征数据。缺点：可能会产生过度匹配问题使用数据类型：数值型和标称型    创建分支伪代码函数createBranch()如下：123456789检测数据集中的">
<meta name="twitter:image" content="https://pic4.zhimg.com/80/v2-4a601bdc74abb553c0873fbd61597035_hd.jpg">
    

    
        <link rel="alternate" href="/" title="Matrix" type="application/atom+xml" />
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/titillium-web/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/3.3.1/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
    


</head>

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                            <p class="subtitle">matrixgardener&#39;s blog</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Essay/">Essay</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Essay/Book/">Book</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Essay/Finance/">Finance</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Essay/Philosophy/">Philosophy</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Sports/">Sports</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Sports/Baseball/">Baseball</a></li></ul></li></ul>
                                    
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="/about/index.html">About</a>
                                </li>
                            
                                <li class="main-nav-list-item" >
                                    <a class="main-nav-list-link" href="https://github.com">index.github</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    uncategorized
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-03机器学习实战-第3章 决策树" class="article article-single article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        03机器学习实战-第3章 决策树
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
        <a href="/2018/01/28/03机器学习实战-第3章 决策树/" class="article-date">
            <time datetime="2018-01-28T11:07:35.000Z" itemprop="datePublished">2018-01-28</time>
        </a>
    </div>

		

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/机器学习/">机器学习</a>
    </div>

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <p>[TOC]</p>
<h1 id="第3章-决策树"><a href="#第3章-决策树" class="headerlink" title="第3章 决策树"></a>第3章 决策树</h1><h2 id="本章内容"><a href="#本章内容" class="headerlink" title="本章内容"></a>本章内容</h2><blockquote>
<ul>
<li>决策树简介  </li>
<li>在数据集中度量一致性  </li>
<li>使用递归构造决策树     </li>
<li>使用Matplotlib绘制树形图   </li>
</ul>
</blockquote>
<h2 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a>决策树的构造</h2><blockquote>
<p>优点：计算复杂度不高，输出易于理解，对中间值得确实不敏感，可以处理不相关特征数据。<br>缺点：可能会产生过度匹配问题<br>使用数据类型：数值型和标称型  </p>
</blockquote>
<p><strong>创建分支伪代码函数createBranch()如下：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">检测数据集中的每个指向是否属于同一个分类：</span><br><span class="line">    IF so return 类标签</span><br><span class="line">    Else</span><br><span class="line">        寻找划分数据集的最好特征</span><br><span class="line">        划分数据集</span><br><span class="line">        创建分支节点</span><br><span class="line">            for 每个划分的子集</span><br><span class="line">                调用函数createBranch并增加返回结果到分支节点中</span><br><span class="line">        return 分支节点</span><br></pre></td></tr></table></figure></p>
<p>上述是一个递归函数</p>
<h2 id="决策树的一般流程"><a href="#决策树的一般流程" class="headerlink" title="决策树的一般流程"></a>决策树的一般流程</h2><blockquote>
<p>(1) 收集数据：可以使用任何方法。<br>(2) 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。<br>(3) 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。<br>(4) 训练算法：构造树的数据结构。<br>(5) 测试算法：使用经验树计算错误率。<br>(6) 使用算法：词步骤可以使用于任何监督学习算法，而使用决策树可能更好地理解数据的内在含义。  </p>
</blockquote>
<p><strong> 摘要</strong></p>
<ol>
<li>信息论相关知识</li>
<li>决策树算法原理</li>
<li>代码实现与解释   </li>
</ol>
<p>今天总结决策树算法，目前建立决策树有三种主要算法：ID3、C4.5以及CART。由于算法知识点比较琐碎，我分成两节来总结。</p>
<p>第一节主要是梳理决策树算法中ID3和C4.5的知识点；第二节主要梳理剪枝技术、CART算法和随机森林算法的知识。</p>
<h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><h3 id="1-信息熵"><a href="#1-信息熵" class="headerlink" title="1.信息熵"></a>1.信息熵</h3><p>在决策树算法中，熵是一个非常非常重要的概念。</p>
<p>一件事发生的概率越小，我们说它所蕴含的信息量越大。</p>
<p>比如：我们听女人能怀孕不奇怪，如果某天听到哪个男人怀孕了，我们就会觉得emmm…信息量很大了。</p>
<p>所以我们这样衡量信息量：</p>
<script type="math/tex; mode=display">
i(y)=-log{P(y)}</script><p>其中，$P(y)$是事件发生的概率。</p>
<p>信息熵就是所有可能发生事件的信息量的期望：  </p>
<script type="math/tex; mode=display">
H(Y)=-\sum_{i=1}^{n}P(y_i)log{P(y_i)}</script><p>表达了$Y$事件发生的不确定度。  </p>
<h3 id="2-条件熵"><a href="#2-条件熵" class="headerlink" title="2.条件熵"></a>2.条件熵</h3><p>条件熵：表示在X给定条件下，$Y$的条件概率分布的熵对$X$的数学期望。其数学推导如下：</p>
<script type="math/tex; mode=display">
\begin{aligned} % requires amsmath; align* for no eq. number
H(Y|X) & =\sum_{x\in{X}}P{(x)}H(Y|X=x) \\
   & =-\sum_{x\in{X}}P(x)\sum_{y\in{Y}}P(y|x)log{P(y|x)}\\
   & =-\sum_{x\in{X}}\sum_{y\in{Y}}P(x,y)log{P(y|x)}
\end{aligned}</script><p>条件熵$H（Y|X）$表示在已知随机变量$X$的条件下随机变量Y的不确定性。注意一下，条件熵中X也是一个变量，意思是在一个变量$X$的条件下（变量$X$的每个值都会取到），另一个变量$Y$的熵对$X$的期望。</p>
<p>举个例子</p>
<p>例：女生决定主不主动追一个男生的标准有两个：颜值和身高，如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>颜值</th>
<th>身高</th>
<th>追不追</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>帅</td>
<td>高</td>
<td>追</td>
</tr>
<tr>
<td>2</td>
<td>帅</td>
<td>不高</td>
<td>追</td>
</tr>
<tr>
<td>3</td>
<td>不帅</td>
<td>高</td>
<td>不追</td>
</tr>
</tbody>
</table>
</div>
<p>上表中随机变量$Y=\{追，不追\}$，$P(Y=追)=2/3$，$P(Y=不追)=1/3$，得到$Y$的熵：</p>
<script type="math/tex; mode=display">
\begin{aligned} % requires amsmath; align* for no eq. number
H(Y) & =-\frac{2}{3}log\frac{2}{3}-\frac{1}{3}log\frac{1}{3} \\
   & =0.918
\end{aligned}</script><p>这里还有一个特征变量$X$，$X=｛高，不高｝$。当$X=高$时，追的个数为1，占1/2，不追的个数为1，占1/2，此时：</p>
<script type="math/tex; mode=display">
H(Y|X=高)=-\frac{1}{2}log\frac{1}{2}-\frac{1}{2}log\frac{1}{2}</script><p>同理：</p>
<script type="math/tex; mode=display">
H(Y|X=不高)=-{1}log{1}-{1}log{1}</script><p>（注意：我们一般约定，当$p=0$时，$plogp=0$）</p>
<p>所以我们得到条件熵的计算公式：  </p>
<script type="math/tex; mode=display">
\begin{aligned} % requires amsmath; align* for no eq. number
H(Y|X=身高) & =P(X=不高)*H(Y|X=不高)+P(X=高)*H(Y|X=高)\\
            & =0.67
\end{aligned}</script><h3 id="3-信息增益"><a href="#3-信息增益" class="headerlink" title="3.信息增益"></a>3.信息增益</h3><p>当我们用另一个变量$X$对原变量$Y$分类后，原变量$Y$的不确定性就会减小了（即熵值减小）。而熵就是不确定性，不确定程度减少了多少其实就是信息增益。这就是信息增益的由来，所以信息增益定义如下：</p>
<script type="math/tex; mode=display">
Gain(Y,X)=H(Y)-H(Y|X)</script><p>此外，信息论中还有互信息、交叉熵等概念，它们与本算法关系不大，这里不展开。 </p>
<h2 id="代码实现与解读"><a href="#代码实现与解读" class="headerlink" title="代码实现与解读"></a>代码实现与解读</h2><p><strong>1.计算给定数据的香浓熵 </strong>    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算给定数据集的香农熵</span></span><br><span class="line"><span class="comment">#从math中导入log函数</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numEntries = len(dataSet)   <span class="comment">#计算实例中的个数</span></span><br><span class="line">    </span><br><span class="line">    labelCounts = &#123;&#125;    <span class="comment">#创建字典，键为标签，值为个数</span></span><br><span class="line">   </span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:    <span class="comment">#the the number of unique elements and their occurance</span></span><br><span class="line">        </span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]    <span class="comment">#得到标签，注意是最后一个标签</span></span><br><span class="line">       </span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():     <span class="comment">#如果标签不在字典已经存在的键中</span></span><br><span class="line">            </span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span>       <span class="comment">#创建名为currentLabel的键，赋值为0</span></span><br><span class="line">          </span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span>     <span class="comment">#标签为currentLabel的个数加1       </span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = float(labelCounts[key])/numEntries    <span class="comment">#计算每一个标签的概率p</span></span><br><span class="line">        </span><br><span class="line">        shannonEnt -= prob * log(prob,<span class="number">2</span>)    <span class="comment">#log base 2利用公式计算香农熵</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">              [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</span><br><span class="line">              [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>,<span class="string">'flippers'</span>]</span><br><span class="line">    <span class="comment">#change to discrete values</span></span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line">myDat,labels=createDataSet()</span><br><span class="line">myDat,labels</span><br></pre></td></tr></table></figure>
<pre><code>([[1, 1, &#39;yes&#39;], [1, 1, &#39;yes&#39;], [1, 0, &#39;no&#39;], [0, 1, &#39;no&#39;], [0, 1, &#39;no&#39;]],
 [&#39;no surfacing&#39;, &#39;flippers&#39;])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">calcShannonEnt(myDat)</span><br></pre></td></tr></table></figure>
<pre><code>0.9709505944546686
</code></pre><p><strong>2.创建选取的数据特征属性划分数据集</strong></p>
<p>程序清单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#按照给定特征划分数据集</span></span><br><span class="line"><span class="comment">#参数解释：dataSet待划分数据集</span></span><br><span class="line"><span class="comment">#axis：划分数据集的特征，这个函数里指函数第几列</span></span><br><span class="line"><span class="comment">#value：特征返回值，指的是特征划分的标准</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []     <span class="comment">#创建一个新列表</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:   <span class="comment">#如果这组数据特征值等于特征返回值的话</span></span><br><span class="line">            </span><br><span class="line">            reducedFeatVec = featVec[:axis]       <span class="comment">#这两行是把原来的数据除掉划分数据的特征那一列 </span></span><br><span class="line">            </span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVec)   <span class="comment">#把列表reduceFeatVect放入retDataSet中</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">splitDataSet(myDat,<span class="number">0</span>,<span class="number">1</span>) </span><br><span class="line"><span class="comment"># myDat=[1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#       [1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#       [1, 0, 'no'],</span></span><br><span class="line"><span class="comment">#       [0, 1, 'no'],</span></span><br><span class="line"><span class="comment">#       [0, 1, 'no']</span></span><br><span class="line"><span class="comment"># 将myDat的第1列按照取出所有等于1的方式划分</span></span><br></pre></td></tr></table></figure>
<pre><code>[[1, &#39;yes&#39;], [1, &#39;yes&#39;], [0, &#39;no&#39;]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">splitDataSet(myDat,<span class="number">0</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[[1, &#39;no&#39;], [1, &#39;no&#39;]]
</code></pre><p><strong>3.根据信息增益准则，选取最好的划分特征</strong></p>
<p>程序清单：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#找到最好的数据集划分方式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeatureToSplit</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span>    <span class="comment">#得到特征个数，减1是因为类别栏     #the last column is used for the labels</span></span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)   <span class="comment">#计算数据原始香农熵</span></span><br><span class="line">   </span><br><span class="line">    bestInfoGain = <span class="number">0.0</span>; bestFeature = <span class="number">-1</span>   <span class="comment">#初始化信息增益和初始化最优特征</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):       </span><br><span class="line">        </span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]  <span class="comment">#熟悉这种写法，括号里面是取了第i个特征的所有值</span></span><br><span class="line">        </span><br><span class="line">        uniqueVals = set(featList)    <span class="comment">#set()，生成一个集合数据类型，其和列表类型一样，不同之处在于</span></span><br><span class="line">                                      <span class="comment">#集合数据类型里面的值不重复，是唯一的</span></span><br><span class="line">        </span><br><span class="line">        newEntropy = <span class="number">0.0</span>    <span class="comment">#初始化新熵为0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:    <span class="comment">#下面这个for函数主要为了计算按第i个特征划分的新熵</span></span><br><span class="line">           </span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)    <span class="comment">#生成按value值划分的数据集</span></span><br><span class="line">            </span><br><span class="line">            prob = len(subDataSet)/float(len(dataSet))   <span class="comment">#计算概率</span></span><br><span class="line">            </span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)    <span class="comment">#计算新熵 </span></span><br><span class="line">       </span><br><span class="line">        infoGain = baseEntropy - newEntropy     <span class="comment">#计算信息增益calculate the info gain; ie reduction in entropy</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):      <span class="comment">#得到最大的信息增益和选取特征 #compare this to the best gain so far</span></span><br><span class="line">            bestInfoGain = infoGain         <span class="comment">#if better than current best, set to best</span></span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature                      <span class="comment">#returns an integer</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># myDat=[1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#       [1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#       [1, 0, 'no'],</span></span><br><span class="line"><span class="comment">#       [0, 1, 'no'],</span></span><br><span class="line"><span class="comment">#       [0, 1, 'no']</span></span><br><span class="line">numFeatures = len(myDat[<span class="number">0</span>]) - <span class="number">1</span> <span class="comment">#得到特征个数，减1是因为类别栏     #the last column is used for the labels</span></span><br><span class="line">    <span class="comment">#计算数据原始香农熵</span></span><br><span class="line"><span class="comment"># numFeatures</span></span><br><span class="line">baseEntropy = calcShannonEnt(myDat)</span><br><span class="line">print(<span class="string">"numFeatures=%d"</span> %numFeatures) </span><br><span class="line">print(<span class="string">"原始熵是："</span>,baseEntropy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#初始化信息增益和初始化最优特征</span></span><br><span class="line">bestInfoGain = <span class="number">0.0</span>; bestFeature = <span class="number">-1</span>     </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):        <span class="comment">#iterate over all the features</span></span><br><span class="line">        <span class="comment">#熟悉这种写法，括号里面是取了第i个特征的所有值</span></span><br><span class="line">    featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> myDat]</span><br><span class="line">    print(<span class="string">"第%d个特征的所有取值"</span> %i,featList)</span><br><span class="line">    </span><br><span class="line">    uniqueVals = set(featList) </span><br><span class="line">    <span class="comment">#初始化新熵为0#get a set of unique values</span></span><br><span class="line">    newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="comment">#下面这个for函数主要为了计算按第i个特征划分的新熵</span></span><br><span class="line">    print(<span class="string">"-简化取值:"</span>,uniqueVals)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            <span class="comment">#生成按value值划分的数据集</span></span><br><span class="line">        subDataSet = splitDataSet(myDat, i, value)</span><br><span class="line">        print(<span class="string">"--按照%d划分取值"</span>% value,subDataSet)</span><br><span class="line">            <span class="comment">#计算概率</span></span><br><span class="line">        prob = len(subDataSet)/float(len(myDat))</span><br><span class="line">            <span class="comment">#计算新熵</span></span><br><span class="line">        print(<span class="string">"---去此值的概率是："</span>,prob)</span><br><span class="line">        newEntropy += prob * calcShannonEnt(subDataSet)   </span><br><span class="line">            <span class="comment">#计算信息增益</span></span><br><span class="line">        print(<span class="string">"---新熵是"</span>,newEntropy)</span><br><span class="line">    infoGain = baseEntropy - newEntropy     <span class="comment">#calculate the info gain; ie reduction in entropy</span></span><br><span class="line">    print(<span class="string">"-----信息增益"</span>,infoGain)</span><br><span class="line">        <span class="comment">#得到最大的信息增益和选取特征</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (infoGain &gt; bestInfoGain):       <span class="comment">#compare this to the best gain so far</span></span><br><span class="line">        bestInfoGain = infoGain         <span class="comment">#if better than current best, set to best</span></span><br><span class="line">        bestFeature = i</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">"此时最好的熵是"</span>,bestInfoGain,<span class="string">"此时最佳特征值是"</span>,bestFeature)</span><br></pre></td></tr></table></figure>
<pre><code>numFeatures=2
原始熵是： 0.9709505944546686
第0个特征的所有取值 [1, 1, 1, 0, 0]
-简化取值: {0, 1}
--按照0划分取值 [[1, &#39;no&#39;], [1, &#39;no&#39;]]
---去此值的概率是： 0.4
---新熵是 0.0
--按照1划分取值 [[1, &#39;yes&#39;], [1, &#39;yes&#39;], [0, &#39;no&#39;]]
---去此值的概率是： 0.6
---新熵是 0.5509775004326937
-----信息增益 0.4199730940219749
此时最好的熵是 0.4199730940219749 此时最佳特征值是 0
第1个特征的所有取值 [1, 1, 0, 1, 1]
-简化取值: {0, 1}
--按照0划分取值 [[1, &#39;no&#39;]]
---去此值的概率是： 0.2
---新熵是 0.0
--按照1划分取值 [[1, &#39;yes&#39;], [1, &#39;yes&#39;], [0, &#39;no&#39;], [0, &#39;no&#39;]]
---去此值的概率是： 0.8
---新熵是 0.8
-----信息增益 0.17095059445466854
此时最好的熵是 0.4199730940219749 此时最佳特征值是 0
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chooseBestFeatureToSplit(myDat)</span><br></pre></td></tr></table></figure>
<pre><code>0
</code></pre><p><strong>从数据集构造决策树算法：其工作原理如下：</strong></p>
<ol>
<li>得到原始数据集  </li>
<li>基于最好的属性值划分数据集（可能存在大于两个分支的数据集划分）    </li>
<li>第一次划分后，数据被向下传递到树分支的下一个节点（可以用递归的思想）</li>
</ol>
<p><strong>递归的条件： </strong><br>程序遍历完所有划分数据集属性，或者每个分支下的所有实例都具有相同的分支。</p>
<p><strong>4.多数表决器</strong></p>
<p>程序清单：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#多数表决器</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    </span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="comment">#for程序用来计数</span></span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys(): </span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    <span class="comment">#排序函数</span></span><br><span class="line">    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p><strong>5.创建决策树</strong>  </p>
<p>程序清单：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建树</span></span><br><span class="line"><span class="comment">#     myDat  = [[1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#               [1, 1, 'yes'],</span></span><br><span class="line"><span class="comment">#               [1, 0, 'no'],</span></span><br><span class="line"><span class="comment">#               [0, 1, 'no'],</span></span><br><span class="line"><span class="comment">#               [0, 1, 'no']]</span></span><br><span class="line"><span class="comment">#     labels = ['no surfacing','flippers']</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet,labels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]<span class="comment">#classLsit里面是dataSet里面的标签</span></span><br><span class="line">    <span class="comment"># 如果数据集的最后一列的第一个值出现的次数=整个集合的数量，也就说只有一个类别，就只直接返回结果就行</span></span><br><span class="line">    <span class="comment"># 第一个停止条件：所有的类标签完全相同，则直接返回该类标签。</span></span><br><span class="line">    <span class="comment"># count() 函数是统计括号中的值在list中出现的次数</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList): <span class="comment">#第一个终止条件：所有类标签都相同，country（）函数用来计数0</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]<span class="comment">#stop splitting when all of the classes are equal</span></span><br><span class="line">    <span class="comment"># 如果数据集只有1列，那么最初出现label次数最多的一类，作为结果</span></span><br><span class="line">    <span class="comment"># 第二个停止条件：使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组。</span></span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>: <span class="comment">#第二个终止条件：用完了所有的特征#stop splitting when there are no more features in dataSet</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]</span><br><span class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]<span class="comment">#得到标签里的所有属性值</span></span><br><span class="line">    uniqueVals = set(featValues)<span class="comment">#得到属性值集合</span></span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:]       <span class="comment">#copy all of labels, so trees don't mess up existing labels</span></span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">createTree(myDat,labels)</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;no surfacing&#39;: {0: &#39;no&#39;, 1: {&#39;flippers&#39;: {0: &#39;no&#39;, 1: &#39;yes&#39;}}}}
</code></pre><p><strong>6.使用决策树进行分类</strong></p>
<p>程序清单：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用决策树分类函数</span></span><br><span class="line"><span class="comment">#三个参数意义：input：决策树；featLabels：特征标签；testVec：测试向量</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inputTree,featLabels,testVec)</span>:</span></span><br><span class="line">    firstStr = inputTree.keys()[<span class="number">0</span>]</span><br><span class="line">    secondDict = inputTree[firstStr]</span><br><span class="line">    featIndex = featLabels.index(firstStr)</span><br><span class="line">    key = testVec[featIndex]</span><br><span class="line">    valueOfFeat = secondDict[key]</span><br><span class="line">    <span class="keyword">if</span> isinstance(valueOfFeat, dict): </span><br><span class="line">        classLabel = classify(valueOfFeat, featLabels, testVec)</span><br><span class="line">    <span class="keyword">else</span>: classLabel = valueOfFeat</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br></pre></td></tr></table></figure>
<p><strong>7.决策树在磁盘中的存储与导入</strong>  </p>
<p>程序清单：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将决策树分类器存储在磁盘中，filename一般保存为txt格式</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeTree</span><span class="params">(inputTree,filename)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fw = open(filename,<span class="string">'w'</span>)</span><br><span class="line">    pickle.dump(inputTree,fw)</span><br><span class="line">    fw.close()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#将磁盘中的对象加载出来，这里filename就是上面函数中的txt文件</span></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grabTree</span><span class="params">(filename)</span>:</span></span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">createTree(myDat,labels)</span><br><span class="line"><span class="comment"># storeTree(myTree,'classifierStorage.txt')</span></span><br><span class="line"><span class="comment"># grabTree('classifierStorage.txt')</span></span><br></pre></td></tr></table></figure>
<pre><code>---------------------------------------------------------------------------

IndexError                                Traceback (most recent call last)

&lt;ipython-input-16-33c9af9c39fa&gt; in &lt;module&gt;()
----&gt; 1 createTree(myDat,labels)
      2 # storeTree(myTree,&#39;classifierStorage.txt&#39;)
      3 # grabTree(&#39;classifierStorage.txt&#39;)


&lt;ipython-input-12-854ee28d5c1d&gt; in createTree(dataSet, labels)
     21     for value in uniqueVals:
     22         subLabels = labels[:]       #copy all of labels, so trees don&#39;t mess up existing labels
---&gt; 23         myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
     24     return myTree


&lt;ipython-input-12-854ee28d5c1d&gt; in createTree(dataSet, labels)
     14         return majorityCnt(classList)
     15     bestFeat = chooseBestFeatureToSplit(dataSet)
---&gt; 16     bestFeatLabel = labels[bestFeat]
     17     myTree = {bestFeatLabel:{}}
     18     del(labels[bestFeat])


IndexError: list index out of range
</code></pre><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ol>
<li>CART决策树</li>
<li>决策树的剪枝技术</li>
<li>Bagging与随机森林</li>
<li>决策树中缺失值的处理</li>
<li>决策树代码</li>
</ol>
<p>注：本节代码对应第九章“树回归”</p>
<h2 id="CART决策树"><a href="#CART决策树" class="headerlink" title="CART决策树"></a>CART决策树</h2><p>为什么同样作为建立决策树的三种算法之一，我们要将CART算法单独拿出来讲。</p>
<p>因为ID3算法和C4.5算法采用了较为复杂的熵来度量，所以它们只能处理分类问题。而CART算法既能处理分类问题，又能处理回归问题。</p>
<p>对于分类树，CART采用基尼指数最小化准则；对于回归树，CART采用平方误差最小化准则</p>
<h3 id="1-CART分类树"><a href="#1-CART分类树" class="headerlink" title="1.CART分类树"></a>1.CART分类树</h3><p>CART分类树与上一节讲述的ID3算法和C4.5算法在原理部分差别不大，唯一的区别在于划分属性的原则。CART选择“基尼指数”作为划分属性的选择。</p>
<p>Gini指数作为一种做特征选择的方式，其表征了特征的不纯度。</p>
<p>在具体的分类问题中，对于数据集D，我们假设有K个类别，每个类别出现的概率为$P_k$，则数据集$D$的基尼指数的表达式为：</p>
<script type="math/tex; mode=display">
Gini=1-\sum_{k=1}^{K}{P_k}^2</script><p>我们取一个极端情况，如果数据集合中的类别只有一类，那么：</p>
<script type="math/tex; mode=display">
Gini(D)=0</script><p>我们发现，当只有一类时，数据的不纯度是最低的，所以Gini指数等于零。Gini(D)越小，则数据集D的纯度越高。</p>
<p>特别地，对于样本D，如果我们选择特征A的某个值a，把D分成$D_1$和$D_2$两部分，则此时，Gini指数为：  </p>
<script type="math/tex; mode=display">
Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)</script><p>与信息增益类似，我们可以计算如下表达式：  </p>
<script type="math/tex; mode=display">
\Delta{Gini(A)}=Gini(D)-Gini(D,A)</script><p>即以特征A划分后，数据不纯度减少的程度。显然，我们在做特征选取时，应该选择最大的一个。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myDat,labels</span><br></pre></td></tr></table></figure>
<pre><code>([[1, 1, &#39;yes&#39;], [1, 1, &#39;yes&#39;], [1, 0, &#39;no&#39;], [0, 1, &#39;no&#39;], [0, 1, &#39;no&#39;]],
 [&#39;no surfacing&#39;, &#39;flippers&#39;])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> featVec <span class="keyword">in</span> myDat: <span class="comment">#the the number of unique elements and their occurance</span></span><br><span class="line">    currentLabel = featVec[<span class="number">-1</span>]</span><br><span class="line">currentLabel</span><br></pre></td></tr></table></figure>
<pre><code>&#39;no&#39;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">labelCounts = &#123;&#125;<span class="comment">#创建字典，键为标签，值为个数</span></span><br><span class="line"><span class="keyword">for</span> featVec <span class="keyword">in</span> myDat: <span class="comment">#the the number of unique elements and their occurance</span></span><br><span class="line">    currentLabel = featVec[<span class="number">-1</span>]<span class="comment">#得到标签，注意是最后一个标签</span></span><br><span class="line">    <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys(): <span class="comment">#如果标签不在字典已经存在的键中</span></span><br><span class="line">        labelCounts[currentLabel] = <span class="number">0</span><span class="comment">#创建名为currentLabel的键，赋值为0</span></span><br><span class="line">    labelCounts[currentLabel] += <span class="number">1</span><span class="comment">#标签为currentLabel的个数加1</span></span><br><span class="line">labelCounts</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;yes&#39;: 2, &#39;no&#39;: 3}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">numFeatures = len(myDat[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">    featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> myDat]</span><br><span class="line">    print(featList)</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 1, 0, 0]
[1, 1, 0, 1, 1]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">myDat[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, &#39;yes&#39;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numFeatures = len(myDat[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">numFeatures</span><br></pre></td></tr></table></figure>
<pre><code>2
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure>
<pre><code>0
1
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> myDat]</span><br><span class="line">classList</span><br></pre></td></tr></table></figure>
<pre><code>[&#39;yes&#39;, &#39;yes&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bestFeat = chooseBestFeatureToSplit(myDat)</span><br><span class="line">bestFeatLabel = labels[bestFeat]</span><br><span class="line">myTree = &#123;bestFeatLabel:&#123;&#125;&#125;</span><br><span class="line">myTree</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;no surfacing&#39;: {}}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> myDat]</span><br><span class="line">featValues</span><br></pre></td></tr></table></figure>
<pre><code>[1, 1, 1, 0, 0]
</code></pre><p>至此，我们完成了决策树算法原理和主要代码的学习。</p>
<p>下一节我们将学习CART算法、随机森林算法以及剪枝技术。</p>
<p>以上原理部分主要来自于《机器学习》—周志华，《统计学习方法》—李航，《机器学习实战》—Peter Harrington。代码部分主要来自于《机器学习实战》，我对代码进行了版本的改进，文中代码用Python3实现，这是机器学习主流语言，本人也会尽力对代码做出较为详尽的注释。</p>
<h2 id="决策树-原理"><a href="#决策树-原理" class="headerlink" title="决策树 原理"></a>决策树 原理</h2><h3 id="决策树-须知概念"><a href="#决策树-须知概念" class="headerlink" title="决策树 须知概念"></a>决策树 须知概念</h3><h4 id="信息熵-amp-信息增益"><a href="#信息熵-amp-信息增益" class="headerlink" title="信息熵 &amp; 信息增益"></a>信息熵 &amp; 信息增益</h4><p><strong>熵</strong>： 熵（entropy）指的是体系的混乱的程度，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。</p>
<p><strong>信息熵（香农熵）</strong>： 是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。例如：火柴有序放在火柴盒里，熵值很低，相反，熵值很高。</p>
<p>信息增益： 在划分数据集前后信息发生的变化称为信息增益。</p>
<h3 id="决策树-工作原理"><a href="#决策树-工作原理" class="headerlink" title="决策树 工作原理"></a>决策树 工作原理</h3><p>如何构造一个决策树?<br>我们使用 createBranch() 方法，如下所示：</p>
<blockquote>
<p>检测数据集中的所有数据的分类标签是否相同:<br>         If so return 类标签<br>            Else:<br>                寻找划分数据集的最好特征（划分之后信息熵最小，也就是信息增益最大的特征）<br>                划分数据集<br>                创建分支节点<br>                        for 每个划分的子集<br>                                调用函数 createBranch （创建分支的函数）并增加返回结果到分支节点中<br>                return 分支节点    </p>
</blockquote>
<p>​        </p>
<h4 id="决策树-开发流程"><a href="#决策树-开发流程" class="headerlink" title="决策树 开发流程"></a>决策树 开发流程</h4><blockquote>
<p>收集数据：可以使用任何方法。<br>准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。<br>分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。<br>训练算法：构造树的数据结构。<br>测试算法：使用经验树计算错误率。（经验树没有搜索到较好的资料，有兴趣的同学可以来补充）<br>使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。     </p>
</blockquote>
<p><strong>决策树 算法特点</strong></p>
<blockquote>
<p>优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。<br>缺点：可能会产生过度匹配问题。<br>适用数据类型：数值型和标称型。</p>
</blockquote>
<h2 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h2><p><strong>1.算法简介</strong></p>
<p>决策树算法是一类常见的分类和回归算法，顾名思义，决策树是基于树的结构来进行决策的。</p>
<p>以二分类为例，我们希望从给定训练集中学得一个模型来对新的样例进行分类。</p>
<p><strong>举个例子</strong></p>
<p>有一个划分是不是鸟类的数据集合，如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>是否会飞</th>
<th>是否会跑</th>
<th>属于鸟类</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>是</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>2</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>3</td>
<td>是</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>4</td>
<td>否</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>5</td>
<td>否</td>
<td>是</td>
<td>否</td>
</tr>
</tbody>
</table>
</div>
<p>这时候我们建立这样一个决策树：  </p>
<p><img src="https://pic4.zhimg.com/80/v2-4a601bdc74abb553c0873fbd61597035_hd.jpg" ,width="400,height=400"></p>
<p>当我们有了一组新的数据时，我们就可以根据这个决策树判断出是不是鸟类。创建决策树的伪代码如下：  </p>
<p><img src="https://pic4.zhimg.com/80/v2-c226901dc50538bd40410e7aae938f47_hd.jpg" ,width="400,eight=400"></p>
<p>生成决策树是一个递归的过程，在决策树算法中，当出现下列三种情况时，导致递归返回： </p>
<p>(1)当前节点包含的样本属于同一种类，无需划分；</p>
<p>(2)当前属性集合为空，或者所有样本在所有属性上取值相同，无法划分；</p>
<p>(3)当前节点包含的样本集合为空，无法划分。</p>
<p><strong>2.属性选择</strong></p>
<p>在决策树算法中，最重要的就是划分属性的选择，即我们选择哪一个属性来进行划分。三种划分属性的主要算法是：ID3、C4.5以及CART。</p>
<p><strong>2.1 ID3算法</strong></p>
<p>ID3算法所采用的度量标准就是我们前面所提到的“信息增益”。当属性a的信息增益最大时，则意味着用a属性划分，其所获得的“纯度”提升最大。我们所要做的，就是找到信息增益最大的属性。由于前面已经强调了信息增益的概念，这里不再赘述。</p>
<p><strong>2.2 C4.5算法</strong></p>
<p>实际上，信息增益准则对于可取值数目较多的属性会有所偏好，为了减少这种偏好可能带来的不利影响，C4.5决策树算法不直接使用信息增益，而是使用“信息增益率”来选择最优划分属性，信息增益率定义为：  </p>
<script type="math/tex; mode=display">
Gain\_ratio(Y,X)=\frac{Gain(Y,X)}{H(X)}</script><p>其中，分子为信息增益，分母为属性$X$的熵。</p>
<p>需要注意的是，增益率准则对可取值数目较少的属性有所偏好。</p>
<p>所以一般这样选取划分属性：<strong>先从候选属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的</strong>。</p>
<p><strong>2.3 CART算法</strong></p>
<p>ID3算法和C4.5算法主要存在三个问题：</p>
<p>(1)每次选取最佳特征来分割数据，并按照该特征的所有取值来进行划分。也就是说，如果一个特征有4种取值，那么数据就将被切成4份，一旦特征被切分后，该特征就不会再起作用，有观点认为这种切分方式过于迅速。</p>
<p>(2)它们不能处理连续型特征。只有事先将连续型特征转换为离散型，才能在上述算法中使用。</p>
<p>(3)会产生过拟合问题。</p>
<p>为了解决上述(1)、(2)问题，产生了CART算法，它主要的衡量指标是基尼系数。为了解决问题(3)，主要采用剪枝技术和随机森林算法，这部分内容，下一次再详细讲述。</p>
<p>上述就是决策树算法的原理部分，下面展示完整代码和注释。代码中主要采用的是ID3算法。</p>

        </div>
        <footer class="article-footer">
            
    <div class="jiathis_style">
    <span class="jiathis_txt">分享到：</span>
    <a class="jiathis_button_qzone">QQ空间</a>
    <a class="jiathis_button_tsina">新浪微博</a>
    <a class="jiathis_button_tqq">腾讯微博</a>
    <a class="jiathis_button_weixin">微信</a>
    <a href="//www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
    <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="//v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<style>
    .jiathis_style div:first-child:not(.jiadiv_01) {
        width: auto !important;
        border: none !important;
    }
    .jiathis_style .jiadiv_01 {
        margin: 10px 0;
        border-radius: 4px;
        border: #e1e1e1 solid 1px;
    }
    .jiathis_style .jiadiv_01 div:first-child {
        display: none;
    }
    .jiathis_style .jiadiv_02 {
        padding: 7px 0 !important;
    }
    .jiathis_style .jiadiv_02 .jiatitle {
        width: 85px;
        border: none;
        height: auto;
        margin: 3px 10px;
        padding: 6px 10px;
        border-radius: 4px;
    }
    .jiathis_style .jiadiv_02 .jiatitle:hover {
        border: none;
    }
    .jiathis_style .jiadiv_02 .jiatitle:nth-child(even) {
        margin-left: 0;
    }
    .jiathis_style .jtico:hover {
        opacity: 1;
    }
    .jiathis_style .ckepopBottom,
    .jiathis_style .centerBottom {
        width: auto !important;
        padding: 5px;
        background: #f7f7f7;
    }
</style>




        </footer>
    </div>
</article>

    <section id="comments">
    
        
    <div id="disqus_thread">
        <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>

    
    </section>



                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="google-plus" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-google-plus"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/matrixgardener" target="_blank" rel="noopener">
                        <i class="icon fa fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="weibo" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-weibo"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="zhihu" href="/" target="_blank" rel="noopener">
                        <i class="icon fa fa-zhihu"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/02/02/三体-维德星际穿越-男主/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            三体-星际穿越
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2018/01/27/01机器学习实战-第1章 机器学习基础/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">01机器学习实战-机器学习基础</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                

            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/30/宽客人生：从物理学家到数量金融大师的传奇/" class="thumbnail">
    
    
        <span style="background-image:url(/image/宽客人生.jpg)" alt="宽客人生：从物理学家到数量金融大师的传奇" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Essay/">Essay</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Essay/Finance/">Finance</a></p>
                            <p class="item-title"><a href="/2018/07/30/宽客人生：从物理学家到数量金融大师的传奇/" class="title">宽客人生：从物理学家到数量金融大师的传奇</a></p>
                            <p class="item-date"><time datetime="2018-07-30T10:04:27.000Z" itemprop="datePublished">2018-07-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/30/欢迎来到我的博客/" class="thumbnail">
    
    
        <span style="background-image:url(/image/img8.jpg)" alt="欢迎来到我的博客" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Sports/">Sports</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Sports/Baseball/">Baseball</a></p>
                            <p class="item-title"><a href="/2018/07/30/欢迎来到我的博客/" class="title">欢迎来到我的博客</a></p>
                            <p class="item-date"><time datetime="2018-07-30T10:04:27.000Z" itemprop="datePublished">2018-07-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/30/hello-world/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2018/07/30/hello-world/" class="title">Hello World</a></p>
                            <p class="item-date"><time datetime="2018-07-30T04:37:35.255Z" itemprop="datePublished">2018-07-30</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/10/“存在主义”的荒诞表述/" class="thumbnail">
    
    
        <span style="background-image:url(/image/matrix.jpg)" alt="“存在主义”的荒诞表述" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Essay/">Essay</a></p>
                            <p class="item-title"><a href="/2018/07/10/“存在主义”的荒诞表述/" class="title">“存在主义”的荒诞表述</a></p>
                            <p class="item-date"><time datetime="2018-07-10T10:04:27.000Z" itemprop="datePublished">2018-07-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/03/30/哲学家都干了什么-下/" class="thumbnail">
    
    
        <span style="background-image:url(/image/philosophy.jpg)" alt="哲学家都干了什么-下" class="thumbnail-image"></span>
    
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Essay/">Essay</a><i class="icon fa fa-angle-right"></i><a class="article-category-link" href="/categories/Essay/Philosophy/">Philosophy</a></p>
                            <p class="item-title"><a href="/2018/03/30/哲学家都干了什么-下/" class="title">哲学家都干了什么-下</a></p>
                            <p class="item-date"><time datetime="2018-03-30T12:24:57.000Z" itemprop="datePublished">2018-03-30</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/">Essay</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/Book/">Book</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/Finance/">Finance</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Essay/Philosophy/">Philosophy</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Sports/">Sports</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Sports/Baseball/">Baseball</a><span class="category-list-count">1</span></li></ul></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Essay/">Essay</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Fight/">Fight</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Injury/">Injury</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python学习/">Python学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Shocking/">Shocking</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/主题测试/">主题测试</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/读书笔记/">读书笔记</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/随想/">随想</a><span class="tag-list-count">6</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/Essay/" style="font-size: 16.67px;">Essay</a> <a href="/tags/Fight/" style="font-size: 10px;">Fight</a> <a href="/tags/Injury/" style="font-size: 10px;">Injury</a> <a href="/tags/Python学习/" style="font-size: 10px;">Python学习</a> <a href="/tags/Shocking/" style="font-size: 10px;">Shocking</a> <a href="/tags/主题测试/" style="font-size: 13.33px;">主题测试</a> <a href="/tags/机器学习/" style="font-size: 16.67px;">机器学习</a> <a href="/tags/读书笔记/" style="font-size: 10px;">读书笔记</a> <a href="/tags/随想/" style="font-size: 20px;">随想</a>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" class="logo"></a>
                </h1>
                <p>&copy; 2018 matrixgardener</p>
                <p>Powered by <a href="//hexo.io/" target="_blank">Hexo</a>. Theme by <a href="//github.com/ppoffice" target="_blank">PPOffice</a></p>
            </div>
            <div class="footer-plugins">
              
    


            </div>
        </div>
    </div>
</footer>

        
    
    <script>
    var disqus_shortname = 'hexo-theme-hueman';
    
    
    var disqus_url = 'http://matrixgardener.github.io/2018/01/28/03机器学习实战-第3章 决策树/';
    
    (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"superSample":2,"width":120,"height":240,"position":"right","hOffset":-20,"vOffset":-40},"mobile":{"show":true,"scale":0.5,"motion":true},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body>
</html>
